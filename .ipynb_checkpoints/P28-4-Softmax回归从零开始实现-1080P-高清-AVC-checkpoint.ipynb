{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "b822eae2-6810-4abb-bdf6-b7bbaefd0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython import display\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "1984c787-f781-4d46-8532-42df569a0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "0076341c-2108-49df-9aca-2f3c8d7cf4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展平每个图像，将它们视为长度为784的向量。\n",
    "# 因为数据集有10个类别，所以网络输出维度为10\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "9a2fd44e-91c1-4cd2-84ab-6442681a7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现softmax\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "de075911-d4cf-41de-9e0b-7c10a66953ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给定一个矩阵X，可以对所有元素求和\n",
    "X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "defdbec8-4e0e-4b83-afca-1efe41d6935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 7., 9.]]),\n",
       " tensor([[ 6.],\n",
       "         [15.]]))"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(0, keepdim=True), X.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2f04207c-e573-49a1-8eb6-dd87cd30a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每个元素变成一个非负数。此外，依据概率原理，每行总和为1\n",
    "X = torch.normal(0, 1, (2, 5)) # 均值为0，方差为1，两行五列的矩阵\n",
    "X_prob = softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "7dfc5319-22af-421d-8318-229163d0de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1682, 0.0705, 0.1609, 0.3840, 0.2164],\n",
       "         [0.1184, 0.3986, 0.2503, 0.0238, 0.2089]]),\n",
       " tensor([1.0000, 1.0000]))"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prob, X_prob.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "70c1c4f9-ad42-4ebb-a4e4-5aa0ea9ad0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现softmax回归模型\n",
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1, w.shape[0])), w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "b3cf0047-8590-466a-b7b2-bca376fbd813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.5000])"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个数据y_hat,其中包含2个样本在3个类别中的预测概率，使用y作为y_hat中概率的索引\n",
    "y = torch.tensor([0, 2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y_hat[[0, 1], y] # [y_hat[0][0], y_hat[1][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "977894a0-8781-4255-92fe-81c1dcca9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现交叉熵损失函数\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "47d296e2-79e0-4abb-9fdb-95f193781ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y_hat, y) # tensor([2.3026, 0.6931]) 样本0的损失，样本1的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "ff1b1ddd-ca59-4072-8867-72f76bf6dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测类别与真实y元素进行比较\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "3de2ca44-e888-4412-bc66-358455a6db0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat, y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "15da5be8-fa1a-449a-a697-a169b3805861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估任意模型net的准确率\n",
    "def evaluate_accuracy(net, data_iter):\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval() # 将模型设置为评估模式\n",
    "    metric = Accumulator(2) # 正确预测数、预测总数\n",
    "    for X, y in data_iter:\n",
    "        metric.add(accuracy(net(X),y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "b1230b50-a70b-4e3e-bf79-f9012792ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulator实例中创建了2个变量，用于分别存储正确预测的数量和预测的总数量\n",
    "class Accumulator:\n",
    "    \"\"\"在`n`个变量上累加。\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "        \n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "0d43c9a3-a10b-415b-b37e-d4c79b6114ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.108"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "bd121555-2c69-4f92-bba8-2ecff7545030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始softmax回归的训练\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    #  isinstance() 函数，是Python中的一个内置函数，用来判断一个函数是否是一个已知的类型\n",
    "    # 知识点：pytorch可以给我们提供两种方式来切换训练和评估(推断)的模式，分别是：model.train() 和 model.eval()。\n",
    "    # 一般用法是：在训练开始之前写上 model.train() ，在测试时写上 model.eval() 。有特殊作用。\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 累加器要累加的变量：训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            # 下面的过程和之前一样，现将梯度设定为0，然后计算梯度，然后更新参数\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数，即是自己实现的，不是内置的\n",
    "            l.sum().backward()  # 此时的l是一个向量，求和并且算梯度\n",
    "            updater(X.shape[0])  # 根据批量大小更新一下\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())  # 记录分类的个数到累加器里\n",
    "    # 返回训练损失和训练精度\n",
    "    # metric[0]是所有的损失累加l.sum()，metric[1]是所有分类正确的样本数，metric[2]是所有的样本数量y.numel()\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ef781-235a-4bbd-bd58-cb6b16d4cb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
